{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1608758781682
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.19.0\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies.\n",
    "\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import azureml.core\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "import joblib \n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
    "\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "import pickle\n",
    "\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "from azureml.core.webservice import LocalWebservice, AciWebservice\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "There are some factors that affects Death Event. We use Kaggle's dataset Heart Failure Clinical Records which contains  information like age, sex, blood pressure, smoke, diabetes, ejection fraction, creatinine phosphokinase, serum_creatinine, serum_sodium, time and we have to predict their death_event.\n",
    "\n",
    "Dataset was uploaded and register as dataset in the workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1608758844869
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code AP3VWNK52 to authenticate.\n",
      "You have logged in. Now let us find all the subscriptions to which you have access...\n",
      "Interactive authentication successfully completed.\n",
      "quick-starts-ws-131542\n",
      "aml-quickstarts-131542\n",
      "southcentralus\n",
      "d7f39349-a66b-446e-aba6-0053c2cf1c11\n"
     ]
    }
   ],
   "source": [
    "# Create a workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1608758861232
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>ml-experiment-1</td><td>quick-starts-ws-131542</td><td><a href=\"https://ml.azure.com/experiments/ml-experiment-1?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-131542/workspaces/quick-starts-ws-131542\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: ml-experiment-1,\n",
       "Workspace: quick-starts-ws-131542)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose a name for experiment\n",
    "experiment_name = 'ml-experiment-1'\n",
    "project_folder = './pipeline-project'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "experiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1608758901773
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# NOTE: update the cluster name to match the existing cluster\n",
    "# Choose a name for your CPU cluster\n",
    "\n",
    "amlcompute_cluster_name = \"notebook131542\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',# for GPU, use \"STANDARD_NC6\"\n",
    "                                                           #vm_priority = 'lowpriority', # optional\n",
    "                                                           max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# For a more detailed view of current AmlCompute status, use get_status().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.get_by_name(workspace, name='heart')\n",
    "ds = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1608758929618
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.833893</td>\n",
       "      <td>0.431438</td>\n",
       "      <td>581.839465</td>\n",
       "      <td>0.418060</td>\n",
       "      <td>38.083612</td>\n",
       "      <td>0.351171</td>\n",
       "      <td>263358.029264</td>\n",
       "      <td>1.39388</td>\n",
       "      <td>136.625418</td>\n",
       "      <td>0.648829</td>\n",
       "      <td>0.32107</td>\n",
       "      <td>130.260870</td>\n",
       "      <td>0.32107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.894809</td>\n",
       "      <td>0.496107</td>\n",
       "      <td>970.287881</td>\n",
       "      <td>0.494067</td>\n",
       "      <td>11.834841</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>97804.236869</td>\n",
       "      <td>1.03451</td>\n",
       "      <td>4.412477</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>0.46767</td>\n",
       "      <td>77.614208</td>\n",
       "      <td>0.46767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25100.000000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212500.000000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262000.000000</td>\n",
       "      <td>1.10000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>582.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>303500.000000</td>\n",
       "      <td>1.40000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7861.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>850000.000000</td>\n",
       "      <td>9.40000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age     anaemia  creatinine_phosphokinase    diabetes  \\\n",
       "count  299.000000  299.000000                299.000000  299.000000   \n",
       "mean    60.833893    0.431438                581.839465    0.418060   \n",
       "std     11.894809    0.496107                970.287881    0.494067   \n",
       "min     40.000000    0.000000                 23.000000    0.000000   \n",
       "25%     51.000000    0.000000                116.500000    0.000000   \n",
       "50%     60.000000    0.000000                250.000000    0.000000   \n",
       "75%     70.000000    1.000000                582.000000    1.000000   \n",
       "max     95.000000    1.000000               7861.000000    1.000000   \n",
       "\n",
       "       ejection_fraction  high_blood_pressure      platelets  \\\n",
       "count         299.000000           299.000000     299.000000   \n",
       "mean           38.083612             0.351171  263358.029264   \n",
       "std            11.834841             0.478136   97804.236869   \n",
       "min            14.000000             0.000000   25100.000000   \n",
       "25%            30.000000             0.000000  212500.000000   \n",
       "50%            38.000000             0.000000  262000.000000   \n",
       "75%            45.000000             1.000000  303500.000000   \n",
       "max            80.000000             1.000000  850000.000000   \n",
       "\n",
       "       serum_creatinine  serum_sodium         sex    smoking        time  \\\n",
       "count         299.00000    299.000000  299.000000  299.00000  299.000000   \n",
       "mean            1.39388    136.625418    0.648829    0.32107  130.260870   \n",
       "std             1.03451      4.412477    0.478136    0.46767   77.614208   \n",
       "min             0.50000    113.000000    0.000000    0.00000    4.000000   \n",
       "25%             0.90000    134.000000    0.000000    0.00000   73.000000   \n",
       "50%             1.10000    137.000000    1.000000    0.00000  115.000000   \n",
       "75%             1.40000    140.000000    1.000000    1.00000  203.000000   \n",
       "max             9.40000    148.000000    1.000000    1.00000  285.000000   \n",
       "\n",
       "       DEATH_EVENT  \n",
       "count    299.00000  \n",
       "mean       0.32107  \n",
       "std        0.46767  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        1.00000  \n",
       "max        1.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload Heart Failure Dataset\n",
    "\n",
    "# data = pd.read_csv(\"heart_failure_clinical_records_dataset.csv\")\n",
    "# data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1608758943770
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./training/train_data.csv\n",
      "Uploaded ./training/train_data.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_0a5662e7ebd143b9911d22c1bfaa9389"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test = train_test_split(data, test_size=0.2, random_state=1 )\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "\n",
    "if \"models\" not in os.listdir():\n",
    "    os.mkdir(\"./models\")\n",
    "    \n",
    "# train.to_csv(\"training/train_data.csv\", index = False)\n",
    "\n",
    "# data_store = ws.get_default_datastore()\n",
    "# data_store.upload(src_dir = \"./training\", target_path = 'udacity-project', overwrite = True,  show_progress = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1608758966340
    }
   },
   "outputs": [],
   "source": [
    "# train_data = Dataset.Tabular.from_delimited_files(path=data_store.path(\"udacity-project/train_data.csv\"))\n",
    "# train=TabularDatasetFactory.from_delimited_files([(datastore, 'trainset.csv')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1608759287765
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Target already exists. Skipping upload for testset.csv\n",
      "Uploaded 0 files\n"
     ]
    }
   ],
   "source": [
    "# test.to_csv(path_or_buf='testset.csv', index=False)\n",
    "# data_store.upload_files(['testset.csv'])\n",
    "\n",
    "# from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# test_data = TabularDatasetFactory.from_delimited_files([(data_store, 'testset.csv')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "TODO: Explain why you chose the automl settings and cofiguration you used below.\n",
    "\n",
    "We are trying to predict DEATH_EVENT, therefore we need to define the task as classification. Also define Featurization as auto and enable early stopping and the primary metric AUC_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1608759338497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Put your automl settings here\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 20,\n",
    "    \"max_concurrent_iterations\": 5,\n",
    "    \"primary_metric\" : 'AUC_weighted'    \n",
    "}\n",
    "\n",
    "# TODO: Put your automl config here\n",
    "automl_config = AutoMLConfig(\n",
    "    \n",
    "    compute_target = compute_target,\n",
    "    task = \"classification\",\n",
    "    training_data = ds,\n",
    "    label_column_name = \"DEATH_EVENT\",   \n",
    "    path = project_folder,\n",
    "    enable_early_stopping= True,\n",
    "    featurization= 'auto',\n",
    "    debug_log = \"automl_errors.log\",\n",
    "    **automl_settings \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1608761042998
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Submit your experiment\n",
    "\n",
    "# Create Pipeline and AutoMLStep / outputs AutoMLStep, TrainingOutput\n",
    "\n",
    "# metrics_output_name = 'metrics_output'\n",
    "# best_model_output_name = 'best_model_output'\n",
    "\n",
    "# metrics_data = PipelineData(name='metrics_data',\n",
    "#                           datastore=data_store,\n",
    "#                           pipeline_output_name=metrics_output_name,\n",
    "#                           training_output=TrainingOutput(type='Metrics'))\n",
    "# model_data = PipelineData(name='model_data',\n",
    "#                           datastore=data_store,\n",
    "#                           pipeline_output_name=best_model_output_name,\n",
    "#                           training_output=TrainingOutput(type='Model'))\n",
    "\n",
    "\n",
    "remote_run = experiment.submit(automl_config, show_output = True)\n",
    "RunDetails(remote_run).show()\n",
    "\n",
    "#Create an AutoMLStep\n",
    "\n",
    "# from azureml.pipeline.steps import AutoMLStep\n",
    "\n",
    "# automl_step = AutoMLStep(\n",
    "#     name='automl_module',\n",
    "#     automl_config=automl_config,\n",
    "#     outputs=[metrics_data, model_data],\n",
    "#     allow_reuse=True)\n",
    "\n",
    "# pipeline = Pipeline(\n",
    "#     description=\"pipeline_with_automlstep\",\n",
    "#     workspace=ws,    \n",
    "#     steps=[automl_step])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1608761124361
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step automl_module [6ff9df1c][c0cb7e0f-e61c-4ff0-8b40-c077482c09c4], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 7f468927-4420-4cd6-aff1-1619b0393a9b\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/ml-experiment-1/runs/7f468927-4420-4cd6-aff1-1619b0393a9b?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-131542/workspaces/quick-starts-ws-131542\n"
     ]
    }
   ],
   "source": [
    "# pipeline_run = experiment.submit(pipeline, show_output=True)\n",
    "remote_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1608761144286
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e1650d8cf549eca1e5fcb17b3baa2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/ml-experiment-1/runs/7f468927-4420-4cd6-aff1-1619b0393a9b?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-131542/workspaces/quick-starts-ws-131542\", \"run_id\": \"7f468927-4420-4cd6-aff1-1619b0393a9b\", \"run_properties\": {\"run_id\": \"7f468927-4420-4cd6-aff1-1619b0393a9b\", \"created_utc\": \"2020-12-23T22:05:22.66392Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2020-12-23T22:51:22.541166Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlstrg131542.blob.core.windows.net/azureml/ExperimentRun/dcid.7f468927-4420-4cd6-aff1-1619b0393a9b/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=1drKeJcTzR3za1QTrfY%2FbjLO6p8PKHXYVFcsTbI3Q8o%3D&st=2020-12-23T23%3A56%3A36Z&se=2020-12-24T08%3A06%3A36Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlstrg131542.blob.core.windows.net/azureml/ExperimentRun/dcid.7f468927-4420-4cd6-aff1-1619b0393a9b/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=674RFa%2BAk0rmQ%2FZ1nEofYQN8S0YwaUGvYBoDJcu5SbQ%3D&st=2020-12-23T23%3A56%3A36Z&se=2020-12-24T08%3A06%3A36Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlstrg131542.blob.core.windows.net/azureml/ExperimentRun/dcid.7f468927-4420-4cd6-aff1-1619b0393a9b/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=pHe78ldqJBO8iE6wDhm5Drmt3RGE6gXqu3sprszYLLw%3D&st=2020-12-23T23%3A56%3A36Z&se=2020-12-24T08%3A06%3A36Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:45:59\"}, \"child_runs\": [{\"run_id\": \"\", \"name\": \"automl_module\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2020-12-23 22:05:33Z] Submitting 1 runs, first five are: 6ff9df1c:d193c7bc-e0ac-4d4e-bc45-a5da19598c8c\\n[2020-12-23 22:51:20Z] Completing processing run id d193c7bc-e0ac-4d4e-bc45-a5da19598c8c.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"dff71688\": {\"node_id\": \"dff71688\", \"name\": \"97add45c-1841-4942-a943-b6c176e80fe6\"}}, \"module_nodes\": {\"6ff9df1c\": {\"node_id\": \"6ff9df1c\", \"name\": \"automl_module\", \"status\": \"NotStarted\"}}, \"edges\": [{\"source_node_id\": \"dff71688\", \"source_node_name\": \"97add45c-1841-4942-a943-b6c176e80fe6\", \"source_name\": \"data\", \"target_name\": \"training_data\", \"dst_node_id\": \"6ff9df1c\", \"dst_node_name\": \"automl_module\"}], \"child_runs\": [{\"run_id\": \"\", \"name\": \"automl_module\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RunDetails(pipeline_run).show()\n",
    "#Take SS\n",
    "\n",
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml.pipeline.core.run:Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
      "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
      "Please check for package conflicts in your python environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 7f468927-4420-4cd6-aff1-1619b0393a9b\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/ml-experiment-1/runs/7f468927-4420-4cd6-aff1-1619b0393a9b?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-131542/workspaces/quick-starts-ws-131542\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pipeline_run.wait_for_completion()\n",
    "\n",
    "# ULIZEUZ: Remove\n",
    "# remote_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gather": {
     "logged": 1608764797803
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml.data.azure_storage_datastore:Path already exists. Skipping download for ./azureml/d193c7bc-e0ac-4d4e-bc45-a5da19598c8c/metrics_data\n"
     ]
    }
   ],
   "source": [
    "best_model, fitted_model = remote_run.get_output()\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "# Take SS\n",
    "\n",
    "# Retrieve metrics of all child runs\n",
    "\n",
    "# metrics_output = pipeline_run.get_pipeline_output(metrics_output_name)\n",
    "# num_file_downloaded = metrics_output.download('.', show_progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1608764810246
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml.data.azure_storage_datastore:Path already exists. Skipping download for ./azureml/d193c7bc-e0ac-4d4e-bc45-a5da19598c8c/model_data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('datatransformer',\n",
       "                 DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
       "                                 feature_sweeping_config=None,\n",
       "                                 feature_sweeping_timeout=None,\n",
       "                                 featurization_config=None, force_text_dnn=None,\n",
       "                                 is_cross_validation=None,\n",
       "                                 is_onnx_compatible=None, logger=None,\n",
       "                                 observer=None, task=None, working_dir=None)),\n",
       "                ('prefittedsoftvotingclassifier',...\n",
       "                                                                                                  max_leaf_nodes=None,\n",
       "                                                                                                  max_samples=None,\n",
       "                                                                                                  min_impurity_decrease=0.0,\n",
       "                                                                                                  min_impurity_split=None,\n",
       "                                                                                                  min_samples_leaf=0.01,\n",
       "                                                                                                  min_samples_split=0.15052631578947367,\n",
       "                                                                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                                                                  n_estimators=10,\n",
       "                                                                                                  n_jobs=1,\n",
       "                                                                                                  oob_score=True,\n",
       "                                                                                                  random_state=None,\n",
       "                                                                                                  verbose=0,\n",
       "                                                                                                  warm_start=False))],\n",
       "                                                                     verbose=False))],\n",
       "                                               flatten_transform=None,\n",
       "                                               weights=[0.1, 0.1, 0.1, 0.1, 0.3,\n",
       "                                                        0.1, 0.1, 0.1]))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import json\n",
    "# with open(metrics_output._path_on_datastore) as f:\n",
    "#     metrics_output_result = f.read()\n",
    "#     \n",
    "# deserialized_metrics_output = json.loads(metrics_output_result)\n",
    "# df = pd.DataFrame(deserialized_metrics_output)\n",
    "# df\n",
    "\n",
    "# Retrieve and save your best automl model.\n",
    "\n",
    "# best_model_output = pipeline_run.get_pipeline_output(best_model_output_name)\n",
    "# num_file_downloaded = best_model_output.download('.', show_progress=True)\n",
    "\n",
    "# with open(best_model_output._path_on_datastore, \"rb\" ) as f:\n",
    "#     best_model = pickle.load(f)\n",
    "# best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gather": {
     "logged": 1608764842947
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('datatransformer',\n",
       "  DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
       "                  feature_sweeping_config=None, feature_sweeping_timeout=None,\n",
       "                  featurization_config=None, force_text_dnn=None,\n",
       "                  is_cross_validation=None, is_onnx_compatible=None, logger=None,\n",
       "                  observer=None, task=None, working_dir=None)),\n",
       " ('prefittedsoftvotingclassifier',\n",
       "  PreFittedSoftVotingClassifier(classification_labels=None,\n",
       "                                estimators=[('61',\n",
       "                                             Pipeline(memory=None,\n",
       "                                                      steps=[('minmaxscaler',\n",
       "                                                              MinMaxScaler(copy=True,\n",
       "                                                                           feature_range=(0,\n",
       "                                                                                          1))),\n",
       "                                                             ('lightgbmclassifier',\n",
       "                                                              LightGBMClassifier(boosting_type='gbdt',\n",
       "                                                                                 class_weight=None,\n",
       "                                                                                 colsample_bytree=0.1988888888888889,\n",
       "                                                                                 importance_type='split',\n",
       "                                                                                 learning_rate=0.026323157894736843,\n",
       "                                                                                 max_bin=390...\n",
       "                                                                                   max_features=0.9,\n",
       "                                                                                   max_leaf_nodes=None,\n",
       "                                                                                   max_samples=None,\n",
       "                                                                                   min_impurity_decrease=0.0,\n",
       "                                                                                   min_impurity_split=None,\n",
       "                                                                                   min_samples_leaf=0.01,\n",
       "                                                                                   min_samples_split=0.15052631578947367,\n",
       "                                                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                                                   n_estimators=10,\n",
       "                                                                                   n_jobs=1,\n",
       "                                                                                   oob_score=True,\n",
       "                                                                                   random_state=None,\n",
       "                                                                                   verbose=0,\n",
       "                                                                                   warm_start=False))],\n",
       "                                                      verbose=False))],\n",
       "                                flatten_transform=None,\n",
       "                                weights=[0.1, 0.1, 0.1, 0.1, 0.3, 0.1, 0.1, 0.1]))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Save the best model\n",
    "joblib.dump(fitted_model, \"models/automl_hearth.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1608764876892
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/automl_hearth.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "ModelPathNotFoundException",
     "evalue": "ModelPathNotFoundException:\n\tMessage: Could not locate the provided model_path description in the set of files uploaded to the run: ['logs/azureml/executionlogs.txt', 'logs/azureml/stderrlogs.txt', 'logs/azureml/stdoutlogs.txt']\n                See https://aka.ms/run-logging for more details.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Could not locate the provided model_path description in the set of files uploaded to the run: ['logs/azureml/executionlogs.txt', 'logs/azureml/stderrlogs.txt', 'logs/azureml/stdoutlogs.txt']\\n                See https://aka.ms/run-logging for more details.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelPathNotFoundException\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-cc7629adf2f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'AutoML Best Model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel2deploy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"description\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mregister_model\u001b[0;34m(self, model_name, model_path, tags, properties, model_framework, model_framework_version, description, datasets, sample_input_dataset, sample_output_dataset, resource_configuration, **kwargs)\u001b[0m\n\u001b[1;32m   2099\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_framework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_framework_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_input_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_input_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m             sample_output_dataset=sample_output_dataset, resource_configuration=resource_configuration, **kwargs)\n\u001b[0m\u001b[1;32m   2102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_dataset_lineage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_run_impl/run_history_facade.py\u001b[0m in \u001b[0;36mregister_model\u001b[0;34m(self, model_name, model_path, tags, properties, model_framework, model_framework_version, asset_id, sample_input_dataset, sample_output_dataset, resource_configuration, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m             raise ModelPathNotFoundException(\n\u001b[1;32m    441\u001b[0m                 \"\"\"Could not locate the provided model_path {} in the set of files uploaded to the run: {}\n\u001b[0;32m--> 442\u001b[0;31m                 See https://aka.ms/run-logging for more details.\"\"\".format(model_path, str(run_files)))\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"prefix\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0martifact_prefix_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mmetadata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelPathNotFoundException\u001b[0m: ModelPathNotFoundException:\n\tMessage: Could not locate the provided model_path description in the set of files uploaded to the run: ['logs/azureml/executionlogs.txt', 'logs/azureml/stderrlogs.txt', 'logs/azureml/stdoutlogs.txt']\n                See https://aka.ms/run-logging for more details.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Could not locate the provided model_path description in the set of files uploaded to the run: ['logs/azureml/executionlogs.txt', 'logs/azureml/stderrlogs.txt', 'logs/azureml/stdoutlogs.txt']\\n                See https://aka.ms/run-logging for more details.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "model = Model.register(model_path = \"./models/automl_hearth.pkl\",\n",
    "                       model_name = \"automl_hearth.pkl\",\n",
    "                       description = \"Best model trained with AutoML\",\n",
    "                       workspace = ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "gather": {
     "logged": 1608765071033
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model Best_Model\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "gather": {
     "logged": 1608767390968
    }
   },
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "myenv = Environment(workspace=ws, name=\"myenv\")\n",
    "# conda_dep = CondaDependencies()\n",
    "\n",
    "## Define the packages needed by the model and scripts\n",
    "# myenv.python.conda_dependencies.add_pip_package(\"inference-schema[numpy-support]\")\n",
    "# myenv.python.conda_dependencies.add_pip_package(\"joblib\")\n",
    "\n",
    "# myenv.docker.base_image = None\n",
    "# myenv.docker.base_dockerfile = \"FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\\nRUN echo \\\"this is test\\\"\"\n",
    "# myenv.inferencing_stack_version = \"latest\"\n",
    "\n",
    "## conda_dep.add_conda_package(\"tensorflow\")\n",
    "## conda_dep.add_conda_package(\"numpy\")\n",
    "## conda_dep.add_conda_package(\"scikit-learn\")\n",
    "## You must list azureml-defaults as a pip dependency\n",
    "## conda_dep.add_pip_package(\"azureml-defaults\")\n",
    "## conda_dep.add_pip_package(\"keras\")\n",
    "## conda_dep.add_pip_package(\"gensim\")\n",
    "\n",
    "## Adds dependencies to PythonSection of myenv\n",
    "## myenv.python.conda_dependencies=conda_dep\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\",\n",
    "                                   environment=myenv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1608771555930
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model Best_Model:2 to /tmp/azureml_3m7dqrs3/Best_Model/2\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry ce398b1861e2422fa9d81168d43a807d.azurecr.io\n",
      "Logging into Docker registry ce398b1861e2422fa9d81168d43a807d.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM ce398b1861e2422fa9d81168d43a807d.azurecr.io/azureml/azureml_2156255e96ba2ed1c4af8bd1a9412df9\n",
      " ---> 77201508465e\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 2a5bdc1dea44\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6ImQ3ZjM5MzQ5LWE2NmItNDQ2ZS1hYmE2LTAwNTNjMmNmMWMxMSIsInJlc291cmNlR3JvdXBOYW1lIjoiYW1sLXF1aWNrc3RhcnRzLTEzMTU0MiIsImFjY291bnROYW1lIjoicXVpY2stc3RhcnRzLXdzLTEzMTU0MiIsIndvcmtzcGFjZUlkIjoiY2UzOThiMTgtNjFlMi00MjJmLWE5ZDgtMTE2OGQ0M2E4MDdkIn0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in c99b313f1f49\n",
      " ---> c7bac3ee4445\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpsza8lxd3.py' /var/azureml-app/main.py\n",
      " ---> Running in e99de616dd58\n",
      " ---> 2b2f50825b74\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 1d78e63998a1\n",
      " ---> 1c81c351539c\n",
      "Successfully built 1c81c351539c\n",
      "Successfully tagged myservice:latest\n",
      "Container (name:nifty_euclid, id:949647b944aa0eaef5039e202133c0813b9804ee7904b545e53929d24232084f) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:4f2cecb6f679f427bc0d71a0509c940451a57a7f3fa9c187ffcb9a6754b96154 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n"
     ]
    }
   ],
   "source": [
    "# Define Deployment\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration()\n",
    "\n",
    "# model = Model(ws, name='hearth')\n",
    "service = Model.deploy(ws, 'myservice', [model], inference_config, deployment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:azureml._model_management._util:Error: Container has crashed. Did your init method fail?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking container health...\n",
      "\n",
      "Container Logs:\n",
      "2020-12-24T00:59:15,761230613+00:00 - rsyslog/run \n",
      "2020-12-24T00:59:15,761980212+00:00 - gunicorn/run \n",
      "2020-12-24T00:59:15,764719608+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_17c0275e5cc0743395fc22f932d02cb3/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_17c0275e5cc0743395fc22f932d02cb3/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_17c0275e5cc0743395fc22f932d02cb3/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_17c0275e5cc0743395fc22f932d02cb3/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_17c0275e5cc0743395fc22f932d02cb3/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2020-12-24T00:59:15,765690006+00:00 - iot-server/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-12-24T00:59:15,849529881+00:00 - iot-server/finish 1 0\n",
      "2020-12-24T00:59:15,850736579+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2020-12-24 00:59:16,405 | root | INFO | Starting up app insights client\n",
      "2020-12-24 00:59:16,405 | root | INFO | Starting up request id generator\n",
      "2020-12-24 00:59:16,406 | root | INFO | Starting up app insight hooks\n",
      "2020-12-24 00:59:16,406 | root | INFO | Invoking user's init function\n",
      "2020-12-24 00:59:16,406 | root | ERROR | User's init function failed\n",
      "2020-12-24 00:59:16,406 | root | ERROR | Encountered Exception Traceback (most recent call last):\n",
      "  File \"/var/azureml-server/aml_blueprint.py\", line 176, in register\n",
      "    main.init()\n",
      "  File \"/var/azureml-app/score.py\", line 16, in init\n",
      "    model = joblib.load(model_path)\n",
      "  File \"/azureml-envs/azureml_17c0275e5cc0743395fc22f932d02cb3/lib/python3.6/site-packages/joblib/numpy_pickle.py\", line 577, in load\n",
      "    with open(filename, 'rb') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/Best_Model/2/automl_hearth.pkl'\n",
      "\n",
      "Worker exiting (pid: 41)\n",
      "Shutting down: Master\n",
      "Reason: Worker failed to boot.\n",
      "2020-12-24T00:59:16,505372202+00:00 - gunicorn/finish 3 0\n",
      "2020-12-24T00:59:16,506543501+00:00 - Exit code 3 is not normal. Killing image.\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ef6c30967089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scoring URI: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 raise WebserviceException('Cannot call {}() when service is {}.'.format(func.__name__, self.state),\n\u001b[1;32m     71\u001b[0m                                           logger=module_logger)\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    609\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                                    \u001b[0mhealth_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_health_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m                                    cleanup_if_failed=False)\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATE_RUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_model_management/_util.py\u001b[0m in \u001b[0;36mcontainer_health_check\u001b[0;34m(docker_port, container, health_url, cleanup_if_failed)\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0;31m# The container has started and crashed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             _raise_for_container_failure(container, cleanup_if_failed,\n\u001b[0;32m--> 743\u001b[0;31m                                          'Error: Container has crashed. Did your init method fail?')\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;31m# The container hasn't crashed, so try to ping the health endpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_model_management/_util.py\u001b[0m in \u001b[0;36m_raise_for_container_failure\u001b[0;34m(container, cleanup, message)\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0mcleanup_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)\n",
    "print(\"scoring URI: \" + service.scoring_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'scoring uri for your service': No schema supplied. Perhaps you meant http://scoring uri for your service?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-2c226808beb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Today is a great day!'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         )\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_native_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL 'scoring uri for your service': No schema supplied. Perhaps you meant http://scoring uri for your service?"
     ]
    }
   ],
   "source": [
    "scoring_uri = 'scoring uri for your service'\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "test_data = json.dumps({'data':[{\n",
    "    'age':75,\n",
    "    'anaemia':0,\n",
    "    'creatinine_phosphokinase':582,\n",
    "    'diabetes':0,\n",
    "    'ejection_fraction':20,\n",
    "    'high_blood_pressure':1,\n",
    "    'platelets':265000,\n",
    "    'serum_creatinine':1.9,\n",
    "    'serum_sodium':130,\n",
    "    'sex':1,\n",
    "    'smoking':0,\n",
    "    'time':4}\n",
    "    ]\n",
    "        })\n",
    "\n",
    "response = requests.post(scoring_uri, data=test_data, headers=headers)\n",
    "\n",
    "print(\"Result:\",response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.save_to_directory('./training',overwrite=False)\n",
    "\n",
    "print(service.get_logs())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a680cd98b1f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "print(response.status_code)\n",
    "print(response.elapsed)\n",
    "print(response.json())\n",
    "\n",
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
