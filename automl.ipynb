{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Dependencies.\n",
        "\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import azureml.core\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "import joblib \n",
        "\n",
        "from azureml.core.model import Model\n",
        "\n",
        "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
        "\n",
        "from azureml.pipeline.core import Pipeline\n",
        "\n",
        "import pickle\n",
        "\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "from azureml.core.webservice import LocalWebservice\n",
        "import requests\n",
        "import json\n",
        "\n",
        "#ULIZEUZ: Check this dependencies\n",
        "#\n",
        "#import csv\n",
        "#\n",
        "#from matplotlib import pyplot as plt\n",
        "#import numpy as np\n",
        "\n",
        "#from sklearn import datasets\n",
        "#import pkg_resources\n",
        "#\n",
        "#from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.19.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1608758781682
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "\n",
        "There are some factors that affects Death Event. We use Kaggle's dataset Heart Failure Clinical Records which contains  information like age, sex, blood pressure, smoke, diabetes, ejection fraction, creatinine phosphokinase, serum_creatinine, serum_sodium, time and we have to predict their death_event.\n",
        "\n",
        "Dataset was uploaded and register as dataset in the workspace\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n",
            "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code AP3VWNK52 to authenticate.\n",
            "You have logged in. Now let us find all the subscriptions to which you have access...\n",
            "Interactive authentication successfully completed.\n",
            "quick-starts-ws-131542\n",
            "aml-quickstarts-131542\n",
            "southcentralus\n",
            "d7f39349-a66b-446e-aba6-0053c2cf1c11\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1608758844869
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose a name for experiment\n",
        "experiment_name = 'ml-experiment-1'\n",
        "project_folder = './pipeline-project'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "\n",
        "experiment\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "Experiment(Name: ml-experiment-1,\nWorkspace: quick-starts-ws-131542)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>ml-experiment-1</td><td>quick-starts-ws-131542</td><td><a href=\"https://ml.azure.com/experiments/ml-experiment-1?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-131542/workspaces/quick-starts-ws-131542\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1608758861232
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: update the cluster name to match the existing cluster\n",
        "# Choose a name for your CPU cluster\n",
        "\n",
        "amlcompute_cluster_name = \"notebook131542\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',# for GPU, use \"STANDARD_NC6\"\n",
        "                                                           #vm_priority = 'lowpriority', # optional\n",
        "                                                           max_nodes=4)\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output=True)\n",
        "\n",
        "# For a more detailed view of current AmlCompute status, use get_status().\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1608758901773
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#upload Heart Failure Dataset\n",
        "\n",
        "data = pd.read_csv(\"heart_failure_clinical_records_dataset.csv\")\n",
        "data.describe()\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "              age     anaemia  creatinine_phosphokinase    diabetes  \\\ncount  299.000000  299.000000                299.000000  299.000000   \nmean    60.833893    0.431438                581.839465    0.418060   \nstd     11.894809    0.496107                970.287881    0.494067   \nmin     40.000000    0.000000                 23.000000    0.000000   \n25%     51.000000    0.000000                116.500000    0.000000   \n50%     60.000000    0.000000                250.000000    0.000000   \n75%     70.000000    1.000000                582.000000    1.000000   \nmax     95.000000    1.000000               7861.000000    1.000000   \n\n       ejection_fraction  high_blood_pressure      platelets  \\\ncount         299.000000           299.000000     299.000000   \nmean           38.083612             0.351171  263358.029264   \nstd            11.834841             0.478136   97804.236869   \nmin            14.000000             0.000000   25100.000000   \n25%            30.000000             0.000000  212500.000000   \n50%            38.000000             0.000000  262000.000000   \n75%            45.000000             1.000000  303500.000000   \nmax            80.000000             1.000000  850000.000000   \n\n       serum_creatinine  serum_sodium         sex    smoking        time  \\\ncount         299.00000    299.000000  299.000000  299.00000  299.000000   \nmean            1.39388    136.625418    0.648829    0.32107  130.260870   \nstd             1.03451      4.412477    0.478136    0.46767   77.614208   \nmin             0.50000    113.000000    0.000000    0.00000    4.000000   \n25%             0.90000    134.000000    0.000000    0.00000   73.000000   \n50%             1.10000    137.000000    1.000000    0.00000  115.000000   \n75%             1.40000    140.000000    1.000000    1.00000  203.000000   \nmax             9.40000    148.000000    1.000000    1.00000  285.000000   \n\n       DEATH_EVENT  \ncount    299.00000  \nmean       0.32107  \nstd        0.46767  \nmin        0.00000  \n25%        0.00000  \n50%        0.00000  \n75%        1.00000  \nmax        1.00000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>anaemia</th>\n      <th>creatinine_phosphokinase</th>\n      <th>diabetes</th>\n      <th>ejection_fraction</th>\n      <th>high_blood_pressure</th>\n      <th>platelets</th>\n      <th>serum_creatinine</th>\n      <th>serum_sodium</th>\n      <th>sex</th>\n      <th>smoking</th>\n      <th>time</th>\n      <th>DEATH_EVENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.00000</td>\n      <td>299.000000</td>\n      <td>299.000000</td>\n      <td>299.00000</td>\n      <td>299.000000</td>\n      <td>299.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>60.833893</td>\n      <td>0.431438</td>\n      <td>581.839465</td>\n      <td>0.418060</td>\n      <td>38.083612</td>\n      <td>0.351171</td>\n      <td>263358.029264</td>\n      <td>1.39388</td>\n      <td>136.625418</td>\n      <td>0.648829</td>\n      <td>0.32107</td>\n      <td>130.260870</td>\n      <td>0.32107</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>11.894809</td>\n      <td>0.496107</td>\n      <td>970.287881</td>\n      <td>0.494067</td>\n      <td>11.834841</td>\n      <td>0.478136</td>\n      <td>97804.236869</td>\n      <td>1.03451</td>\n      <td>4.412477</td>\n      <td>0.478136</td>\n      <td>0.46767</td>\n      <td>77.614208</td>\n      <td>0.46767</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>40.000000</td>\n      <td>0.000000</td>\n      <td>23.000000</td>\n      <td>0.000000</td>\n      <td>14.000000</td>\n      <td>0.000000</td>\n      <td>25100.000000</td>\n      <td>0.50000</td>\n      <td>113.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>4.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>51.000000</td>\n      <td>0.000000</td>\n      <td>116.500000</td>\n      <td>0.000000</td>\n      <td>30.000000</td>\n      <td>0.000000</td>\n      <td>212500.000000</td>\n      <td>0.90000</td>\n      <td>134.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>73.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>60.000000</td>\n      <td>0.000000</td>\n      <td>250.000000</td>\n      <td>0.000000</td>\n      <td>38.000000</td>\n      <td>0.000000</td>\n      <td>262000.000000</td>\n      <td>1.10000</td>\n      <td>137.000000</td>\n      <td>1.000000</td>\n      <td>0.00000</td>\n      <td>115.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>70.000000</td>\n      <td>1.000000</td>\n      <td>582.000000</td>\n      <td>1.000000</td>\n      <td>45.000000</td>\n      <td>1.000000</td>\n      <td>303500.000000</td>\n      <td>1.40000</td>\n      <td>140.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>203.000000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>95.000000</td>\n      <td>1.000000</td>\n      <td>7861.000000</td>\n      <td>1.000000</td>\n      <td>80.000000</td>\n      <td>1.000000</td>\n      <td>850000.000000</td>\n      <td>9.40000</td>\n      <td>148.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>285.000000</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1608758929618
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(data, test_size=0.2, random_state=1 )\n",
        "\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "\n",
        "if \"models\" not in os.listdir():\n",
        "    os.mkdir(\"./models\")\n",
        "    \n",
        "train.to_csv(\"training/train_data.csv\", index = False)\n",
        "\n",
        "data_store = ws.get_default_datastore()\n",
        "data_store.upload(src_dir = \"./training\", target_path = 'udacity-project', overwrite = True,  show_progress = True)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading an estimated of 1 files\n",
            "Uploading ./training/train_data.csv\n",
            "Uploaded ./training/train_data.csv, 1 files out of an estimated total of 1\n",
            "Uploaded 1 files\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "$AZUREML_DATAREFERENCE_0a5662e7ebd143b9911d22c1bfaa9389"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1608758943770
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = Dataset.Tabular.from_delimited_files(path=data_store.path(\"udacity-project/train_data.csv\"))\n",
        "# train=TabularDatasetFactory.from_delimited_files([(datastore, 'trainset.csv')])\n"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1608758966340
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.to_csv(path_or_buf='testset.csv', index=False)\n",
        "data_store.upload_files(['testset.csv'])\n",
        "\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "test_data = TabularDatasetFactory.from_delimited_files([(data_store, 'testset.csv')])\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading an estimated of 1 files\n",
            "Target already exists. Skipping upload for testset.csv\n",
            "Uploaded 0 files\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1608759287765
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below.\n",
        "\n",
        "We are trying to predict DEATH_EVENT, therefore we need to define the task as classification. Also define Featurization as auto and enable early stopping and the primary metric AUC_weighted"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\n",
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 20,\n",
        "    \"max_concurrent_iterations\": 5,\n",
        "    \"primary_metric\" : 'AUC_weighted'    \n",
        "}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(\n",
        "    \n",
        "    compute_target = compute_target,\n",
        "    task = \"classification\",\n",
        "    training_data = train_data,\n",
        "    label_column_name = \"DEATH_EVENT\",   \n",
        "    path = project_folder,\n",
        "    enable_early_stopping= True,\n",
        "    featurization= 'auto',\n",
        "    debug_log = \"automl_errors.log\",\n",
        "    **automl_settings \n",
        ")"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1608759338497
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "\n",
        "# Create Pipeline and AutoMLStep / outputs AutoMLStep, TrainingOutput\n",
        "\n",
        "metrics_output_name = 'metrics_output'\n",
        "best_model_output_name = 'best_model_output'\n",
        "\n",
        "metrics_data = PipelineData(name='metrics_data',\n",
        "                           datastore=data_store,\n",
        "                           pipeline_output_name=metrics_output_name,\n",
        "                           training_output=TrainingOutput(type='Metrics'))\n",
        "model_data = PipelineData(name='model_data',\n",
        "                           datastore=data_store,\n",
        "                           pipeline_output_name=best_model_output_name,\n",
        "                           training_output=TrainingOutput(type='Model'))\n",
        "\n",
        "\n",
        "# remote_run = experiment.submit(automl_config, show_output = True)\n",
        "# RunDetails(remote_run).show()\n",
        "\n",
        "#Create an AutoMLStep\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "automl_step = AutoMLStep(\n",
        "    name='automl_module',\n",
        "    automl_config=automl_config,\n",
        "    outputs=[metrics_data, model_data],\n",
        "    allow_reuse=True)\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    description=\"pipeline_with_automlstep\",\n",
        "    workspace=ws,    \n",
        "    steps=[automl_step])\n"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1608761042998
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run = experiment.submit(pipeline, show_output=True)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created step automl_module [6ff9df1c][c0cb7e0f-e61c-4ff0-8b40-c077482c09c4], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun 7f468927-4420-4cd6-aff1-1619b0393a9b\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/ml-experiment-1/runs/7f468927-4420-4cd6-aff1-1619b0393a9b?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-131542/workspaces/quick-starts-ws-131542\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1608761124361
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(pipeline_run).show()\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11e1650d8cf549eca1e5fcb17b3baa2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/ml-experiment-1/runs/7f468927-4420-4cd6-aff1-1619b0393a9b?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-131542/workspaces/quick-starts-ws-131542\", \"run_id\": \"7f468927-4420-4cd6-aff1-1619b0393a9b\", \"run_properties\": {\"run_id\": \"7f468927-4420-4cd6-aff1-1619b0393a9b\", \"created_utc\": \"2020-12-23T22:05:22.66392Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlstrg131542.blob.core.windows.net/azureml/ExperimentRun/dcid.7f468927-4420-4cd6-aff1-1619b0393a9b/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=e60uYNWsJF0qQ9PlHlXya%2FBqUqjpcVmr6OJvlk7vHWc%3D&st=2020-12-23T21%3A55%3A44Z&se=2020-12-24T06%3A05%3A44Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlstrg131542.blob.core.windows.net/azureml/ExperimentRun/dcid.7f468927-4420-4cd6-aff1-1619b0393a9b/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=ifQZCAgyzxQ%2BVefwZotzAptHTdAt9ophUnX%2FTJ5Flyc%3D&st=2020-12-23T21%3A55%3A44Z&se=2020-12-24T06%3A05%3A44Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlstrg131542.blob.core.windows.net/azureml/ExperimentRun/dcid.7f468927-4420-4cd6-aff1-1619b0393a9b/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=VO2PThi5nYWAjqipJ%2BhkP4ckxbJ4VAL4v1akgLDFF%2FI%3D&st=2020-12-23T21%3A55%3A44Z&se=2020-12-24T06%3A05%3A44Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:07:36\"}, \"child_runs\": [{\"run_id\": \"\", \"name\": \"automl_module\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2020-12-23 22:05:33Z] Submitting 1 runs, first five are: 6ff9df1c:d193c7bc-e0ac-4d4e-bc45-a5da19598c8c\\n\", \"graph\": {\"datasource_nodes\": {\"dff71688\": {\"node_id\": \"dff71688\", \"name\": \"97add45c-1841-4942-a943-b6c176e80fe6\"}}, \"module_nodes\": {\"6ff9df1c\": {\"node_id\": \"6ff9df1c\", \"name\": \"automl_module\", \"status\": \"NotStarted\"}}, \"edges\": [{\"source_node_id\": \"dff71688\", \"source_node_name\": \"97add45c-1841-4942-a943-b6c176e80fe6\", \"source_name\": \"data\", \"target_name\": \"training_data\", \"dst_node_id\": \"6ff9df1c\", \"dst_node_name\": \"automl_module\"}], \"child_runs\": [{\"run_id\": \"\", \"name\": \"automl_module\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1608761144286
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run.wait_for_completion()\n",
        "\n",
        "# ULIZEUZ: Remove\n",
        "# remote_run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:azureml.pipeline.core.run:Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
            "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
            "Please check for package conflicts in your python environment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRunId: 7f468927-4420-4cd6-aff1-1619b0393a9b\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/ml-experiment-1/runs/7f468927-4420-4cd6-aff1-1619b0393a9b?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-131542/workspaces/quick-starts-ws-131542\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve metrics of all child runs\n",
        "\n",
        "metrics_output = pipeline_run.get_pipeline_output(metrics_output_name)\n",
        "num_file_downloaded = metrics_output.download('.', show_progress=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431425670
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(metrics_output._path_on_datastore) as f:\n",
        "    metrics_output_result = f.read()\n",
        "    \n",
        "deserialized_metrics_output = json.loads(metrics_output_result)\n",
        "df = pd.DataFrame(deserialized_metrics_output)\n",
        "df\n",
        "\n",
        "# Retrieve and save your best automl model.\n",
        "\n",
        "best_model_output = pipeline_run.get_pipeline_output(best_model_output_name)\n",
        "num_file_downloaded = best_model_output.download('.', show_progress=True)\n",
        "\n",
        "with open(best_model_output._path_on_datastore, \"rb\" ) as f:\n",
        "    best_model = pickle.load(f)\n",
        "best_model\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.steps\n",
        "\n",
        "# ULIZEUZ: Remove\n",
        "# best_model, fitted_model = remote_run.get_output()\n",
        "# print(best_model)\n",
        "# print(fitted_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model\n",
        "joblib.dump(best_model, \"models/automl_hearth.pkl\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431426111
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "description = 'AutoML Best Model'\n",
        "\n",
        "model2deploy = remote_run.register_model(\"description\")\n",
        "\n",
        "print(remote_run.model_id)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431435189
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model.register(model_path = \"./models\",\n",
        "                       model_name = \"Best_Model\",\n",
        "                       description = \"Best model trained with AutoML\",\n",
        "                       workspace = ws)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the environment\n",
        "myenv = Environment(name=\"myenv\")\n",
        "# conda_dep = CondaDependencies()\n",
        "\n",
        "# Define the packages needed by the model and scripts\n",
        "myenv.python.conda_dependencies.add_pip_package(\"inference-schema[numpy-support]\")\n",
        "myenv.python.conda_dependencies.add_pip_package(\"joblib\")\n",
        "\n",
        "myenv.docker.base_image = None\n",
        "myenv.docker.base_dockerfile = \"FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\\nRUN echo \\\"this is test\\\"\"\n",
        "myenv.inferencing_stack_version = \"latest\"\n",
        "\n",
        "# conda_dep.add_conda_package(\"tensorflow\")\n",
        "# conda_dep.add_conda_package(\"numpy\")\n",
        "# conda_dep.add_conda_package(\"scikit-learn\")\n",
        "# You must list azureml-defaults as a pip dependency\n",
        "# conda_dep.add_pip_package(\"azureml-defaults\")\n",
        "# conda_dep.add_pip_package(\"keras\")\n",
        "# conda_dep.add_pip_package(\"gensim\")\n",
        "\n",
        "# Adds dependencies to PythonSection of myenv\n",
        "# myenv.python.conda_dependencies=conda_dep\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\",\n",
        "                                   environment=myenv)\n",
        "# Define Deployment\n",
        "\n",
        "# ULIZEUZ: Check Docker\n",
        "deployment_config = LocalWebservice.deploy_configuration(#port=6789) \n",
        "\n",
        "# model = Model(ws, name='sentiment')\n",
        "service = Model.deploy(ws, 'myservice', [model], inference_config, deployment_config)\n",
        "\n",
        "service.wait_for_deployment(True)\n",
        "print(service.state)\n",
        "print(\"scoring URI: \" + service.scoring_uri)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scoring_uri = 'scoring uri for your service'\n",
        "headers = {'Content-Type':'application/json'}\n",
        "\n",
        "test_data = json.dumps({'text': 'Today is a great day!'})\n",
        "\n",
        "response = requests.post(scoring_uri, data=test_data, headers=headers)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.status_code)\n",
        "print(response.elapsed)\n",
        "print(response.json())\n",
        "\n",
        "service.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}